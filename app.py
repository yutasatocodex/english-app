import streamlit as st
import pandas as pd
from pypdf import PdfReader
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime
from st_click_detector import click_detector
import html
import traceback
import re
from openai import OpenAI

# --- è¨­å®š: ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆãƒ¯ã‚¤ãƒ‰è¡¨ç¤ºï¼‰ ---
st.set_page_config(layout="wide")

# --- è¨­å®š1: Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆé€£æº ---
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]

def get_gspread_client():
    creds_dict = dict(st.secrets["gcp_service_account"])
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    client = gspread.authorize(creds)
    return client

# --- è¨­å®š2: OpenAI (ChatGPT) è¾æ›¸æ©Ÿèƒ½ ---
def translate_with_gpt(text: str) -> dict:
    client = OpenAI(api_key=st.secrets["openai"]["api_key"])
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¼·åŒ–ï¼šå“è©ã‚„ä»–ã®æ„å‘³ã‚‚å–å¾—ã™ã‚‹
    prompt = (
        f"Explain the English word '{text}' for a Japanese learner.\n"
        "Output format must be exactly like this (3 lines):\n"
        "JAPANESE_MEANING: (The most common Japanese meaning)\n"
        "POS: (Part of Speech, e.g., Verb, Noun)\n"
        "DETAILS: (Other meanings, synonyms, or a brief nuance explanation in Japanese)"
    )
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "You are a helpful English-Japanese dictionary AI."},
            {"role": "user", "content": prompt},
        ],
    )
    raw_content = response.choices[0].message.content.strip()
    
    # çµæœã‚’è§£æã—ã¦è¾æ›¸ã«ã™ã‚‹
    result = {"meaning": "???", "pos": "", "details": ""}
    for line in raw_content.split('\n'):
        if line.startswith("JAPANESE_MEANING:"):
            result["meaning"] = line.replace("JAPANESE_MEANING:", "").strip()
        elif line.startswith("POS:"):
            result["pos"] = line.replace("POS:", "").strip()
        elif line.startswith("DETAILS:"):
            result["details"] = line.replace("DETAILS:", "").strip()
            
    # è§£æå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if result["meaning"] == "???":
        result["meaning"] = raw_content
        
    return result

# --- PDFãƒ†ã‚­ã‚¹ãƒˆæ•´å½¢é–¢æ•°ï¼ˆã“ã“ãŒé‡è¦ï¼ï¼‰ ---
def clean_pdf_text(text):
    if not text:
        return ""
    # 1. ãƒã‚¤ãƒ•ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆè¡Œæœ«ã® - ï¼‰ã‚’ã¤ãªã’ã‚‹
    text = re.sub(r'-\n', '', text)
    # 2. åŸºæœ¬çš„ãªæ”¹è¡Œã‚’ã‚¹ãƒšãƒ¼ã‚¹ã«ç½®æ›ï¼ˆæ–‡ç« ã‚’ã¤ãªã’ã‚‹ï¼‰
    text = re.sub(r'(?<!\n)\n(?!\n)', ' ', text)
    # 3. é€£ç¶šã™ã‚‹ç©ºç™½ã‚’1ã¤ã«ã¾ã¨ã‚ã‚‹
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
if "last_clicked_id" not in st.session_state:
    st.session_state.last_clicked_id = ""
if "clicked_ids" not in st.session_state:
    st.session_state.clicked_ids = set()
if "current_translation" not in st.session_state:
    st.session_state.current_translation = None

# --- ã‚¢ãƒ—ãƒªç”»é¢æ§‹æˆ ---
st.title("ğŸ¤– AI English PDF Dictionary")

# 2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼ˆå·¦ï¼šPDFæ“ä½œã€å³ï¼šè¾æ›¸çµæœï¼‰
col1, col2 = st.columns([2, 1])

with col1:
    st.markdown("### ğŸ“„ PDF Viewer")
    uploaded_file = st.file_uploader("Choose a PDF file", type="pdf")

if uploaded_file is not None:
    try:
        reader = PdfReader(uploaded_file)
        total_pages = len(reader.pages)

        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ã«é…ç½®ï¼‰
        with col1:
            page_num = st.number_input(
                f"Page (Total {total_pages})", min_value=1, max_value=total_pages, value=1, step=1
            )
            
            page = reader.pages[page_num - 1]
            raw_text = page.extract_text()

            if raw_text:
                # PDFãƒ†ã‚­ã‚¹ãƒˆã‚’ãã‚Œã„ã«æ•´å½¢ï¼ˆæ”¹è¡Œå‰Šé™¤ï¼‰
                clean_text = clean_pdf_text(raw_text)
                
                # HTMLç”Ÿæˆï¼ˆå˜èªã”ã¨ã«ãƒªãƒ³ã‚¯åŒ–ï¼‰
                html_content = """
                <style>
                    .pdf-container {
                        font-family: 'Helvetica Neue', Arial, sans-serif;
                        background-color: #ffffff;
                        color: #222222;
                        padding: 25px;
                        border-radius: 8px;
                        border: 1px solid #e0e0e0;
                        font-size: 18px; /* æ–‡å­—ã‚’å°‘ã—å¤§ãã */
                        line-height: 1.8; /* è¡Œé–“ã‚’åºƒã‚ã« */
                        box-shadow: 0 2px 5px rgba(0,0,0,0.05);
                        text-align: justify; /* ä¸¡ç«¯æƒãˆã§è¦‹ã‚„ã™ã */
                    }
                    .word-link { 
                        color: #222222; 
                        text-decoration: none; 
                        cursor: pointer; 
                        padding: 0 2px;
                    }
                    .word-link:hover { 
                        background-color: #e3f2fd; 
                        color: #1565c0;
                        border-radius: 3px;
                    }
                    /* ç¿»è¨³æ¸ˆã¿å˜èªï¼ˆé»„è‰²ãƒãƒ¼ã‚«ãƒ¼ï¼‰ */
                    .highlighted {
                        background-color: #fff9c4; 
                        border-bottom: 2px solid #fbc02d;
                        color: #000000;
                    }
                </style>
                <div class='pdf-container'>
                """

                words = clean_text.split()
                # å˜èªãƒªã‚¹ãƒˆã‚’è¾æ›¸åŒ–ï¼ˆã‚¯ãƒªãƒƒã‚¯åˆ¤å®šç”¨ï¼‰
                id_to_word = {}
                
                for i, w in enumerate(words):
                    current_id = f"w{i}"
                    id_to_word[current_id] = w
                    
                    # è¨˜å·ã‚’é™¤å»ã—ã¦è¡¨ç¤ºç”¨ã®å˜èªã‚’ä½œã‚‹
                    safe_w = html.escape(w)
                    
                    # æ—¢ã«ã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸå˜èªãªã‚‰ãƒãƒ¼ã‚«ãƒ¼ã‚¯ãƒ©ã‚¹ã‚’ã¤ã‘ã‚‹
                    css_class = "word-link"
                    if current_id in st.session_state.clicked_ids:
                        css_class += " highlighted"
                    
                    html_content += f"<a href='#' id='{current_id}' class='{css_class}'>{safe_w}</a> "
                
                html_content += "</div>"

                # ã‚¯ãƒªãƒƒã‚¯æ¤œçŸ¥
                clicked_id = click_detector(html_content)

                # --- ã‚¯ãƒªãƒƒã‚¯æ™‚ã®å‡¦ç† ---
                if clicked_id and clicked_id != st.session_state.last_clicked_id:
                    st.session_state.last_clicked_id = clicked_id
                    st.session_state.clicked_ids.add(clicked_id) # ãƒãƒ¼ã‚«ãƒ¼ç”¨ã«è¨˜æ†¶
                    
                    # ç¿»è¨³å¯¾è±¡ã®å˜èªã‚’å–å¾—
                    if clicked_id in id_to_word:
                        target_word = id_to_word[clicked_id]
                        clean_word = target_word.strip(".,!?\"'()[]{}:;")
                        
                        if clean_word:
                            # OpenAIã§è¾æ›¸æ¤œç´¢
                            # æš—è»¢ã‚’é˜²ããŸã‚ st.spinner ã¯ä½¿ã‚ãšã€ãƒˆãƒ¼ã‚¹ãƒˆé€šçŸ¥ã ã‘å‡ºã™
                            st.toast(f"ğŸ” Searching: {clean_word}...", icon="ğŸ¤–")
                            
                            try:
                                result = translate_with_gpt(clean_word)
                                
                                # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ï¼ˆç”»é¢å†æç”»ç”¨ï¼‰
                                st.session_state.current_translation = {
                                    "word": clean_word,
                                    "result": result
                                }

                                # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆä¿å­˜ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰çš„ã«å®Ÿè¡Œï¼‰
                                client = get_gspread_client()
                                sheet_name = st.secrets["sheet_config"]["sheet_name"]
                                sheet = client.open(sheet_name).sheet1
                                date_str = datetime.now().strftime("%Y-%m-%d")
                                row = [clean_word, result["meaning"], date_str]
                                sheet.append_row(row)
                                
                            except Exception as e:
                                st.error(f"Error: {e}")
                    
                    # ç”»é¢æ›´æ–°ï¼ˆã“ã‚Œã§ãƒãƒ¼ã‚«ãƒ¼ãŒåæ˜ ã•ã‚Œã‚‹ï¼‰
                    st.rerun()

            else:
                st.warning("No text extracted from this page.")
    except Exception as e:
        col1.error(f"Error reading PDF: {e}")

# --- å³ã‚«ãƒ©ãƒ ï¼šè¾æ›¸çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢ï¼ˆå›ºå®šè¡¨ç¤ºï¼‰ ---
with col2:
    st.markdown("### ğŸ’¡ Dictionary")
    
    current = st.session_state.current_translation
    if current:
        word = current["word"]
        res = current["result"]
        
        # è¾æ›¸ã‚«ãƒ¼ãƒ‰ã®ãƒ‡ã‚¶ã‚¤ãƒ³
        st.markdown(f"""
        <div style="padding: 20px; border: 2px solid #4CAF50; border-radius: 10px; background-color: #f9fff9;">
            <h2 style="color: #2e7d32; margin-top: 0;">{word}</h2>
            <p><b>{res['pos']}</b></p>
            <hr>
            <h3 style="color: #333;">{res['meaning']}</h3>
            <p style="color: #666; font-size: 0.9em;">{res['details']}</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.caption("âœ… Automatically saved to Spreadsheet")
    else:
        st.info("ğŸ‘ˆ Tap any word in the PDF to see the meaning here.")
